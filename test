[fedaggre.py:104] -------------------------------------------Start a New------------------------------------------------
[fedaggre.py:105] Training on cuda using PyTorch 2.1.1+cu118
[fedaggre.py:97] logfile_info : test(01)
[fedaggre.py:97] wandb_project : test
[fedaggre.py:97] wandb : 0
[fedaggre.py:97] client_dataset : cifar100
[fedaggre.py:97] num_class : 100
[fedaggre.py:97] num_clients : 4
[fedaggre.py:97] batch_size : 64
[fedaggre.py:97] dirichlet_alpha : 0.1
[fedaggre.py:97] model_name : ViT-B/32
[fedaggre.py:97] round : 3
[fedaggre.py:97] device : cuda
[fedaggre.py:97] dataset_path : ../dataset
[fedaggre.py:97] margin : 0.2
[fedaggre.py:97] local_lr : 0.001
[fedaggre.py:97] local_momentum : 0.9
[fedaggre.py:97] local_weight_decay : 1e-4
[fedaggre.py:97] local_epoch : 1
[fedaggre.py:97] use_mlp : 1
[fedaggre.py:97] use_softmax : 0
[fedaggre.py:97] use_before_fc_emb : 1
[fedaggre.py:97] gene_num : 1000
[fedaggre.py:97] reverse_textemb : 0
[fedaggre.py:97] mlp_hiddenlayer_num : 2048
[fedaggre.py:97] use_timm : 0
[fedaggre.py:97] only_test_training_labels : 0
[fedaggre.py:97] select_client_num : 0
[fedaggre.py:97] use_privacy_generator : 0
[fedaggre.py:97] strategy : CANAL
[fedaggre.py:97] meaningful_anchor : 0
[fedaggre.py:97] theoretical_bound : 1
[fedaggre.py:97] save_model_param : 0
[fedaggre.py:97] save_client_param : 0
[fedaggre.py:97] save_client_model : 0
[fedaggre.py:97] yaml_name : test.yaml
[fedaggre.py:97] log_name : test_test(01)_cifar100_3_4
[fedaggre.py:97] device : cuda
[fedaggre.py:290] [client0]: {0: 14, 1: 1, 2: 1, 3: 1, 4: 495, 5: 1, 6: 398, 7: 1, 8: 1, 9: 156, 10: 1, 11: 1, 12: 417, 13: 28, 14: 10, 15: 125, 16: 125, 17: 1, 18: 94, 19: 14, 20: 1, 21: 471, 22: 1, 23: 1, 24: 44, 25: 117, 26: 355, 27: 1, 28: 481, 29: 477, 31: 495, 32: 8, 33: 498, 34: 5, 35: 1, 36: 1, 37: 1, 38: 1, 39: 1, 40: 105, 41: 52, 42: 481, 43: 20, 44: 2, 45: 53, 46: 1, 47: 1, 49: 1, 50: 29, 51: 334, 52: 404, 53: 194, 54: 1, 55: 3, 56: 1, 57: 500, 58: 1, 59: 6, 60: 76, 61: 1, 62: 1, 63: 298, 64: 14, 65: 106, 66: 496, 67: 1, 68: 1, 69: 1, 70: 1, 71: 122, 72: 500, 73: 3, 74: 1, 75: 1, 76: 1, 77: 12, 78: 83, 79: 64, 80: 1, 81: 485, 82: 143, 83: 16, 84: 1, 85: 1, 86: 6, 87: 1, 88: 488, 89: 1, 90: 1, 91: 1, 92: 1, 93: 1, 94: 1, 95: 500, 96: 1, 97: 2, 98: 29, 99: 1}
[fedaggre.py:290] [client1]: {0: 133, 1: 454, 7: 15, 8: 248, 9: 1, 10: 498, 11: 33, 12: 78, 13: 86, 14: 490, 15: 259, 16: 14, 19: 12, 20: 7, 21: 25, 22: 21, 23: 499, 24: 1, 25: 383, 26: 145, 27: 498, 29: 23, 30: 1, 31: 5, 34: 3, 37: 38, 40: 361, 41: 109, 43: 198, 44: 187, 45: 86, 46: 499, 47: 114, 48: 484, 50: 467, 52: 96, 53: 306, 54: 179, 56: 8, 63: 137, 65: 4, 67: 3, 68: 499, 69: 5, 70: 360, 71: 1, 74: 3, 76: 1, 77: 469, 78: 284, 79: 153, 80: 387, 82: 196, 83: 481, 85: 2, 87: 22, 89: 338, 91: 101, 92: 424, 93: 499, 94: 1, 96: 351, 99: 125}
[fedaggre.py:290] [client2]: {0: 343, 1: 44, 2: 22, 5: 305, 6: 102, 8: 251, 10: 1, 11: 144, 13: 192, 16: 361, 17: 499, 18: 405, 19: 474, 22: 477, 30: 498, 33: 2, 35: 391, 37: 1, 40: 3, 41: 333, 42: 19, 43: 28, 45: 306, 49: 496, 54: 320, 56: 470, 58: 495, 59: 2, 61: 449, 62: 499, 64: 2, 65: 389, 66: 2, 67: 7, 69: 494, 70: 139, 73: 488, 74: 475, 75: 1, 76: 41, 77: 19, 78: 133, 79: 282, 80: 112, 82: 161, 86: 138, 87: 476, 91: 391, 92: 1, 94: 2, 96: 148, 99: 374}
[fedaggre.py:290] [client3]: {0: 10, 1: 1, 2: 477, 3: 499, 4: 5, 5: 194, 7: 484, 9: 343, 11: 322, 12: 5, 13: 194, 15: 116, 18: 1, 20: 492, 21: 4, 22: 1, 24: 455, 27: 1, 28: 19, 30: 1, 32: 492, 34: 492, 35: 108, 36: 499, 37: 460, 38: 499, 39: 499, 40: 31, 41: 6, 43: 254, 44: 311, 45: 55, 47: 385, 48: 16, 49: 3, 50: 4, 51: 166, 55: 497, 56: 21, 58: 4, 59: 492, 60: 424, 61: 50, 63: 65, 64: 484, 65: 1, 66: 2, 67: 489, 71: 377, 73: 9, 74: 21, 75: 498, 76: 457, 79: 1, 81: 15, 83: 3, 84: 499, 85: 497, 86: 356, 87: 1, 88: 12, 89: 161, 90: 499, 91: 7, 92: 74, 94: 496, 97: 498, 98: 471}
[fedaggre.py:297] *** Round [1] ***
[fedaggre.py:318] Round [1] select clients number is [0, 1, 2, 3]
loss=tensor(67.9545, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6063, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5872, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5847, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5985, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5983, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5956, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5905, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5970, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5954, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5938, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6062, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5948, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5947, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5956, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6086, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5905, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5948, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6017, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6082, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5982, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5838, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5939, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5983, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6001, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5847, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5976, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6063, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5815, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5893, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5873, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5867, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5938, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6032, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5985, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6055, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5946, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6031, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5957, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5940, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6071, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5977, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5962, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6127, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5909, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5949, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5955, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5993, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6034, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5921, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6067, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6077, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5999, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6048, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5985, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6041, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6031, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6027, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5926, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5822, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5803, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5931, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5994, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6029, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5929, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5897, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5967, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6005, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5989, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6015, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5903, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6054, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5940, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5961, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5970, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5875, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5940, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5795, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5931, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5924, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5881, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6075, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5874, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5826, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5917, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5935, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5975, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5931, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5907, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5951, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5887, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5960, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5875, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6053, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5930, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6055, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5963, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5938, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5965, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5923, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6038, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6102, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5930, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5944, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5954, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5980, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6040, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5929, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6171, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5901, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5790, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5973, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5912, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6021, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5956, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5913, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5943, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5883, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5958, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6026, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5986, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6061, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5895, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5986, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5969, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5778, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5897, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5981, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5833, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5852, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5911, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6017, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5828, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5921, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6009, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5750, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5883, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5830, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5934, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6011, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5846, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6165, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5975, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5907, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5773, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5918, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6081, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5961, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5903, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5976, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5921, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5878, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6066, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6022, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5952, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5964, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5814, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5937, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6064, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
[fedaggre.py:266] Round[1]TrainClient0:[1/1], Loss:0.901, DataLength:10498, mean/var:4.1705803871154785/587.1547241210938
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5911, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6002, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5891, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5887, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5937, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(1.7992, device='cuda:0', grad_fn=<SumBackward0>)
bsz=2
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
[fedaggre.py:281] Round[1]Val_Client[0], Accu[0.010], Loss[0.900]
loss=tensor(68.5701, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6002, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5966, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5888, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5959, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5916, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5901, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5871, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5987, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6043, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6001, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6009, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6157, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5985, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5955, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5922, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5915, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5952, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5914, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5926, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5979, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5928, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5940, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5964, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5948, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5990, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5841, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5912, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5918, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6091, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5955, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5968, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5969, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5924, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5888, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5973, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6032, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5970, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5966, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6020, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5865, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6020, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5924, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5912, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5976, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5916, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5864, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5905, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5915, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5932, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5956, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5959, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6009, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6095, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5985, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6010, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5952, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5819, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5860, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6006, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5925, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5846, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5990, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6051, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6020, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5923, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6002, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5932, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5942, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5893, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5921, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5847, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5811, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5850, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5804, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5918, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5972, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6006, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5880, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5858, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5890, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5948, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5872, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5923, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5913, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6021, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5799, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5965, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5951, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5924, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5968, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5938, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5951, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5975, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5900, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6019, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5911, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5844, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5906, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5914, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5950, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5816, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5903, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6013, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5999, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6038, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5920, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5923, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5982, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5972, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6016, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5967, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5901, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6058, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5858, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5891, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5911, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5913, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5935, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5901, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6031, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5961, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5915, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5920, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5896, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5933, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5952, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5821, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5968, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5879, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6047, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5935, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5877, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6065, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5952, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6052, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5825, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5835, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5953, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5920, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5924, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5939, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5946, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5904, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5900, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5947, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5890, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5938, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5979, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5879, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5932, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5867, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5947, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5943, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5866, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5948, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5975, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5848, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5890, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
[fedaggre.py:266] Round[1]TrainClient1:[1/1], Loss:0.901, DataLength:11910, mean/var:3.413175344467163/455.2210693359375
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5865, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5940, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5900, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5862, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5865, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5916, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5885, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5970, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5811, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5919, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5847, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6006, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5872, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5995, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6056, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5872, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5916, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5857, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5906, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5887, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5951, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5946, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5955, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5857, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5980, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5870, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5956, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(5.3982, device='cuda:0', grad_fn=<SumBackward0>)
bsz=6
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
[fedaggre.py:281] Round[1]Val_Client[1], Accu[0.010], Loss[0.900]
loss=tensor(67.9778, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6051, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6071, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6013, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5961, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5912, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5930, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5968, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5953, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6018, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5982, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6032, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6094, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6012, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6012, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5932, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6028, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6003, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5958, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5962, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6015, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6020, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5986, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5960, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6112, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5988, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5958, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5975, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6013, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6019, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6062, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5998, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6055, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6028, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6017, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6031, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5927, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6069, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5973, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6120, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5983, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5900, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5998, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5984, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6016, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6020, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6012, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5962, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5988, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5976, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5981, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6081, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5985, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6025, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6056, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6053, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6045, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5996, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6141, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5891, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5965, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6010, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5937, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5970, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6068, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5962, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5931, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5942, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6075, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5944, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5943, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5981, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6002, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6013, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6021, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6018, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6054, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6039, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5997, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6049, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6086, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5997, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5909, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6113, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6001, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5965, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6033, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6044, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5979, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5984, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6053, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5977, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5927, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6005, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5957, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6019, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5984, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5965, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5988, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5980, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5923, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5976, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5966, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6063, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6033, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6118, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6032, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5970, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5936, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6035, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5935, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5948, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5997, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6027, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6067, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6023, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5995, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6053, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5998, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6066, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5952, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5985, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6021, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6057, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5963, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5995, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6063, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6014, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5974, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6001, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5997, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6027, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6101, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6076, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6021, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6025, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5917, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6008, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5968, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6021, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5992, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6023, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5942, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6024, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5974, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5976, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6010, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5999, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6052, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5983, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6041, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5948, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5931, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6026, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6074, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5952, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5992, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5938, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5993, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6025, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6061, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6036, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5907, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6011, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5926, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5995, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5982, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6039, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5998, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6019, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5953, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6017, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5995, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5936, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5950, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5904, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5984, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5917, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6010, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5970, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5993, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5998, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5996, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5986, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6026, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6029, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5960, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6007, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5987, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5945, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
[fedaggre.py:266] Round[1]TrainClient2:[1/1], Loss:0.901, DataLength:12207, mean/var:3.459541082382202/484.31109619140625
loss=tensor(42.3060, device='cuda:0', grad_fn=<SumBackward0>)
bsz=47
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
[fedaggre.py:281] Round[1]Val_Client[2], Accu[0.010], Loss[0.900]
loss=tensor(67.8840, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5821, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5852, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5914, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5814, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5806, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5978, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5800, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5747, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5982, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5843, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5828, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5844, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5918, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5819, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5896, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5825, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5894, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5854, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5818, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5834, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5772, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5884, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5847, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5834, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5912, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5861, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5960, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5857, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5888, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5842, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5875, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5860, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5867, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5795, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5889, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5804, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5796, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5887, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5798, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5775, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5823, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5847, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5873, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5855, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5850, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5851, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5869, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5894, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5906, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5931, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5883, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5933, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5899, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5805, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5830, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5860, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5818, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5914, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5884, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5858, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5844, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5838, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5822, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5827, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5902, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5844, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5825, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5844, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5934, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5832, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5859, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5885, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5797, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5816, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5871, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5903, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5793, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5951, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5923, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5846, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5781, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5889, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5835, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5895, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5847, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5844, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5911, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5791, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5767, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5895, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5858, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5831, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5847, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5896, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5864, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5838, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5817, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5803, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5843, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5906, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5773, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5891, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5871, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5843, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5912, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5837, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5858, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5886, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5809, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5791, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5888, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5881, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5850, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5927, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5769, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5711, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5852, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5860, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5853, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5827, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5864, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5867, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5726, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5821, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5850, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5822, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5888, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5952, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5873, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5768, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5827, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5850, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5842, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5715, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5886, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5936, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5856, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5849, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5833, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5896, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5907, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5856, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5793, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5851, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5857, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5719, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5765, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5861, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5807, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5892, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5870, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5887, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5834, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5820, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5796, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5897, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5888, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5807, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5843, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5768, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5835, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5915, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5876, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5863, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5785, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5903, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5778, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5768, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5897, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5856, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5798, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5767, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5795, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5855, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5851, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5940, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5836, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5835, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5759, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5836, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5902, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5896, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5853, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5727, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5861, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5873, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5869, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5918, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5790, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5805, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5804, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5813, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5794, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5890, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5868, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5861, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5758, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5780, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5898, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5864, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5879, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5896, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5921, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5835, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5905, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5826, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5832, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5830, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5757, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5911, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5793, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5787, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5835, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5797, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5845, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5768, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5832, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5876, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5821, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5813, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5845, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
[fedaggre.py:266] Round[1]TrainClient3:[1/1], Loss:0.900, DataLength:15385, mean/var:2.3762640953063965/280.216796875
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5820, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5824, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5834, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5788, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5725, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5912, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5802, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5839, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5734, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5901, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5806, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5907, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5835, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5787, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5838, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5898, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5715, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5817, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(22.4930, device='cuda:0', grad_fn=<SumBackward0>)
bsz=25
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
[fedaggre.py:281] Round[1]Val_Client[3], Accu[0.010], Loss[0.900]
[fedaggre.py:360] *** Round[1]: Server_Test_Accu[0.010] *** 
[fedaggre.py:297] *** Round [2] ***
[fedaggre.py:318] Round [2] select clients number is [0, 1, 2, 3]
[fedaggre.py:255] Totally 1024 Pseudo labels
use pseudo
loss=tensor(115.2017, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2180, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.1979, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2124, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.1971, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2052, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2085, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.1884, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2109, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2026, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.1998, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2116, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.1976, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2010, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.1987, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(93.5988, device='cuda:0', grad_fn=<AddBackward0>)
bsz=104
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6002, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5950, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6003, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6039, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6091, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6100, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5996, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6051, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6105, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6036, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6052, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6081, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6034, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6028, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6114, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6017, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5950, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6026, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5952, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6036, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6064, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6042, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5981, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6053, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5939, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6057, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6029, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6006, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5951, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6087, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5947, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6053, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6015, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6040, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6117, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6010, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5981, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5991, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6059, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6010, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6093, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6059, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6023, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6060, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6105, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6013, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6071, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5994, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6084, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6002, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5999, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5994, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6083, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5959, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6043, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6028, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6129, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5933, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5998, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6041, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5996, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6006, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5971, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6060, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6080, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6121, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6012, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6067, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5959, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6009, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6089, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6025, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6086, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6063, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5925, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6050, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5962, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5896, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5999, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5993, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6003, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5991, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5834, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6043, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6029, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6070, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6070, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5936, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5994, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6007, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6037, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6003, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5973, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6076, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6011, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6045, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6018, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6029, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5910, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6032, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5918, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5936, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5994, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6045, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6028, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6084, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6031, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6026, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6093, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5975, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6014, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6055, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6082, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6073, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6067, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6086, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6025, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6040, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5982, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5901, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6022, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5990, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6167, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5941, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6072, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6111, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5983, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6001, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6032, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6077, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6021, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6091, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5959, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5983, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6091, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6043, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5928, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5990, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6047, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5938, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5880, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6016, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
[fedaggre.py:266] Round[2]TrainClient0:[1/1], Loss:0.900, DataLength:10498, mean/var:0.03141481429338455/7.571813966933405e-06
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5956, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6042, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6028, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5966, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5977, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5933, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(1.7986, device='cuda:0', grad_fn=<SumBackward0>)
bsz=2
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
[fedaggre.py:281] Round[2]Val_Client[0], Accu[0.010], Loss[0.900]
[fedaggre.py:255] Totally 1024 Pseudo labels
use pseudo
loss=tensor(115.2009, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2000, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.1972, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2023, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2062, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2208, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2128, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.1981, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.1995, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2021, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.1969, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.1892, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2087, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.1999, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.1873, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(93.6103, device='cuda:0', grad_fn=<AddBackward0>)
bsz=104
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5966, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5979, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6017, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5957, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5960, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6049, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6083, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5996, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6042, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5984, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6020, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5978, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6005, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6029, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6034, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5937, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6001, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5929, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6009, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5969, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5998, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5955, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5947, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5964, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5955, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6004, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5930, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6028, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6042, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6008, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5988, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5993, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6021, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5945, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5996, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6002, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5947, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5993, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6002, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5972, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6004, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5987, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5933, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5901, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6010, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6109, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5907, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6065, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5972, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5899, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5909, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5838, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6005, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5884, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6042, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6087, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6017, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5959, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5936, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6027, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5961, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6013, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5921, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5993, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5959, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5942, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5938, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5978, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6014, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5941, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6044, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5919, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5996, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5991, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5985, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5883, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5990, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5972, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6011, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6021, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6117, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6096, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6034, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6063, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5950, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5978, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5931, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5953, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5964, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5921, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5989, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6020, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5942, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5967, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6026, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5910, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6003, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6002, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5856, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5973, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5939, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5939, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5885, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6020, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5981, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5982, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5923, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6002, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6028, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5964, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5888, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5989, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6069, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5946, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5969, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5842, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5967, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5931, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5964, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5924, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5905, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5969, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6000, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5929, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6033, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5966, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5973, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5921, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5948, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5934, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5971, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6016, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5922, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5983, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5889, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5985, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5929, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6054, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5954, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6021, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5929, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5976, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
[fedaggre.py:266] Round[2]TrainClient1:[1/1], Loss:0.900, DataLength:11910, mean/var:0.03924969956278801/7.1364779614668805e-06
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5934, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5979, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5907, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6017, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5959, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5940, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5930, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5997, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5925, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5953, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6018, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5979, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6061, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5916, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5943, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6064, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5898, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5986, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6011, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5972, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5940, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5956, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5983, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5903, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5893, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5982, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6026, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5950, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(5.3979, device='cuda:0', grad_fn=<SumBackward0>)
bsz=6
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
[fedaggre.py:281] Round[2]Val_Client[1], Accu[0.010], Loss[0.900]
[fedaggre.py:255] Totally 1024 Pseudo labels
use pseudo
loss=tensor(115.1998, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2175, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.1950, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2124, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2164, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2080, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.1960, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2106, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2207, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2137, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.1955, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.1932, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2213, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.1983, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2065, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(93.6199, device='cuda:0', grad_fn=<AddBackward0>)
bsz=104
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6080, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5987, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6179, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6184, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6062, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6166, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6036, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6062, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5980, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6085, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6022, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6022, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6061, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6021, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6073, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6114, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6153, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6082, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6122, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6016, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6128, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6101, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6103, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6187, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6149, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6102, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6125, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6103, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6085, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6098, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6084, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6000, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6104, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6068, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6057, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6113, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6055, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6130, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5976, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5992, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6036, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6021, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5963, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6114, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6119, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6074, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6243, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6069, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6067, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6070, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6053, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6121, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6067, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6106, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5965, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6052, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6025, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6257, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6024, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6083, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6100, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5987, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6100, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6104, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6101, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6052, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6101, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6121, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6079, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6050, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6002, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6020, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6072, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6107, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6002, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6026, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6104, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6050, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6018, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6042, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6071, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6116, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6121, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6232, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6058, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6085, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6119, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6054, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5992, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6058, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6142, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6196, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6137, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6246, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6048, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6041, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6068, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6083, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6148, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6024, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6103, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6020, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6142, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6011, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6071, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6108, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6087, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6028, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6085, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6110, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6117, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6006, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6023, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6067, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6127, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6141, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6037, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6145, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6048, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6147, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6167, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6048, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6134, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6032, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6082, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6052, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6095, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6125, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6091, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6089, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6159, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6105, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5999, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6115, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6212, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6007, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6157, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6081, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5999, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6159, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6060, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6172, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6124, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6195, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6135, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6015, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6149, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6017, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6103, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6096, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6080, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6106, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6093, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6068, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6172, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6127, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5914, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6043, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6084, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6106, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6035, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6100, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6056, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6072, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6167, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6105, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5981, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6070, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6083, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6133, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5961, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6010, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6157, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
[fedaggre.py:266] Round[2]TrainClient2:[1/1], Loss:0.900, DataLength:12207, mean/var:0.03400275111198425/8.211276508518495e-06
loss=tensor(57.6172, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(42.3087, device='cuda:0', grad_fn=<SumBackward0>)
bsz=47
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
[fedaggre.py:281] Round[2]Val_Client[2], Accu[0.010], Loss[0.900]
[fedaggre.py:255] Totally 1024 Pseudo labels
use pseudo
loss=tensor(115.1875, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.1824, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.1915, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2013, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.1898, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2003, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.1930, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.1830, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.1935, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.1963, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.1876, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.1886, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2022, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2029, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2031, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(93.5978, device='cuda:0', grad_fn=<AddBackward0>)
bsz=104
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5895, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5915, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5861, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5970, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5936, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5862, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5885, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5895, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5873, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5932, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5961, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5982, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5931, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5923, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5916, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5903, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5915, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5874, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5889, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5931, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5827, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5910, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5926, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5954, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5953, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5921, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5931, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5905, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5958, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5910, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5976, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5895, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5958, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5883, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5922, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5898, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5924, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5851, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5917, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5900, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5911, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5925, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5917, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5841, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5921, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5920, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5910, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5942, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5953, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5926, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5909, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5900, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5816, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5956, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5834, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5930, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6002, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5853, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5859, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5954, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5928, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5947, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5875, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5977, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5828, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5936, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5844, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5896, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5895, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5859, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5884, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5947, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5889, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5917, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5925, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5932, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5885, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5962, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5893, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5934, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5923, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5941, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5906, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5840, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5936, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5944, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5819, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5904, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5885, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5937, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5891, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5920, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5901, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5956, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5877, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5933, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5932, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5966, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5872, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5900, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5924, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5850, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5920, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5886, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5921, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5917, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5908, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5843, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5936, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5883, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5937, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5899, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5933, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5884, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5939, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5884, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5901, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5880, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5846, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5952, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5848, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5941, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5891, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5920, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5920, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5825, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5937, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5956, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5932, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5884, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5907, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5884, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5879, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5859, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5843, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5940, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5961, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5861, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5990, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6035, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5802, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5934, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5897, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5858, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5872, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5926, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5896, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5901, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5891, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5926, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5871, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5891, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5929, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5970, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5912, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5994, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5876, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5943, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5908, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5926, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5997, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5880, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5971, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5824, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5951, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5949, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5918, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5868, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5899, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5825, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5939, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5915, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5885, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5832, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5846, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5853, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5953, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5866, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5879, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5890, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5885, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5884, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5962, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5889, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5828, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5877, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5850, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5850, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5904, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5917, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5917, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5992, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5932, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5813, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5857, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5933, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5910, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5831, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5916, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5847, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5824, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5828, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5934, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5866, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5914, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
[fedaggre.py:266] Round[2]TrainClient3:[1/1], Loss:0.900, DataLength:15385, mean/var:0.03316415473818779/7.1787621891417075e-06
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5854, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5864, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5912, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5867, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5820, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5960, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5883, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5865, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5885, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5831, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5915, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5864, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5922, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5871, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5883, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5869, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5890, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5862, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5969, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(22.4941, device='cuda:0', grad_fn=<SumBackward0>)
bsz=25
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
[fedaggre.py:281] Round[2]Val_Client[3], Accu[0.010], Loss[0.900]
[fedaggre.py:360] *** Round[2]: Server_Test_Accu[0.010] *** 
[fedaggre.py:297] *** Round [3] ***
[fedaggre.py:318] Round [3] select clients number is [0, 1, 2, 3]
[fedaggre.py:255] Totally 1024 Pseudo labels
use pseudo
loss=tensor(115.2121, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2176, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2103, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.1923, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2061, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.1999, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2018, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2044, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2153, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.1972, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2168, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2019, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.1971, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2051, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2040, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(93.6009, device='cuda:0', grad_fn=<AddBackward0>)
bsz=104
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6047, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6046, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6047, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6055, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6036, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6106, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5981, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6009, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6019, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5968, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6051, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6031, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6032, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6013, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6059, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6053, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5879, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6055, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6035, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6064, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5993, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6003, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6006, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5992, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5933, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6177, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6093, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5976, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6024, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6000, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6021, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6103, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6113, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5980, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6044, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6004, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5957, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6009, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6023, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5984, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6142, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6000, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5995, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6057, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6019, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5953, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6017, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6092, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5975, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6009, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5951, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5976, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6018, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5994, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5991, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5937, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5970, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6089, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5919, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6103, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5986, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5939, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5960, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6065, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5948, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6068, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5966, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5996, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5934, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6084, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6030, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6065, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6031, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6074, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6120, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5951, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5980, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6226, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5979, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5877, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6022, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6100, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6046, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5922, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6075, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5950, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6009, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6061, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6017, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5952, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6029, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6060, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5999, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6069, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5983, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6043, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6022, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6030, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5999, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6002, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6001, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5938, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5939, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5928, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5987, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5979, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5969, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6058, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5968, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6097, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6054, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5960, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5944, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6047, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6011, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6047, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6061, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5996, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6091, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6041, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6008, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6109, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6138, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6029, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6113, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6018, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6086, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6058, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6023, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5979, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5998, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5943, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6078, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6081, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5906, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5950, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5954, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5971, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6006, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6052, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6042, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5980, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
[fedaggre.py:266] Round[3]TrainClient0:[1/1], Loss:0.900, DataLength:10498, mean/var:0.03143120929598808/7.82616734795738e-06
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6108, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5956, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6039, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6072, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5968, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6041, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(1.8020, device='cuda:0', grad_fn=<SumBackward0>)
bsz=2
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
[fedaggre.py:281] Round[3]Val_Client[0], Accu[0.010], Loss[0.900]
[fedaggre.py:255] Totally 1024 Pseudo labels
use pseudo
loss=tensor(115.2066, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2018, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.1977, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.1945, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.1904, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.1869, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.1938, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.1918, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2058, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.1784, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2040, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2033, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.1977, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.1938, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2003, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(93.6014, device='cuda:0', grad_fn=<AddBackward0>)
bsz=104
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6059, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5969, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6035, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5962, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5916, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5901, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6013, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5996, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5949, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5913, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5989, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5991, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6101, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5959, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6084, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5922, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5936, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6016, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6111, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5984, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6028, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6039, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5928, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5920, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5961, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5974, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5930, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5953, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5955, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5994, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5984, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5949, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6053, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5996, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6093, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5947, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6039, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6001, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6047, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6002, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6010, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6047, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6004, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6019, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6000, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6004, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6037, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5941, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5961, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6030, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5963, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5995, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5968, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5993, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6018, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5988, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5925, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5968, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5937, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5958, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5936, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6001, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6018, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6049, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6052, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6005, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5925, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5941, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5906, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5989, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6004, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5999, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5980, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5839, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5970, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5964, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5971, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5969, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5899, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5891, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6036, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5977, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5947, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5928, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5939, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6091, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5945, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5982, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5991, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6050, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6019, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5925, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6061, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5881, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5909, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5928, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6040, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6050, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5963, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5896, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5980, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5905, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5949, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6020, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5944, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5897, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6118, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5818, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5917, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5999, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5903, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6025, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5937, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6041, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5907, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5961, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5995, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5923, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6050, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6035, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5979, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5944, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5942, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6075, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6021, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5965, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6004, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6041, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5996, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6001, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6042, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6004, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5968, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5920, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5917, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6123, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5931, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5919, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5842, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6037, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6085, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5953, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
[fedaggre.py:266] Round[3]TrainClient1:[1/1], Loss:0.900, DataLength:11910, mean/var:0.0394432507455349/7.918131814221852e-06
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6048, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6022, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5949, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6000, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6073, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5931, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5955, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5993, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5938, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5912, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5990, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5887, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5927, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5905, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5971, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5982, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5920, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5996, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6033, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5971, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5915, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6005, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5981, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5982, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6019, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6016, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5877, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6030, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(5.4014, device='cuda:0', grad_fn=<SumBackward0>)
bsz=6
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
[fedaggre.py:281] Round[3]Val_Client[1], Accu[0.010], Loss[0.900]
[fedaggre.py:255] Totally 1024 Pseudo labels
use pseudo
loss=tensor(115.2149, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2074, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2048, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2061, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2128, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2192, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2088, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2091, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2186, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2021, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2115, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2067, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2053, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2082, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2069, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(93.6223, device='cuda:0', grad_fn=<AddBackward0>)
bsz=104
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6177, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6047, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6094, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6106, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6115, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6077, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5998, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6160, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6108, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6242, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5991, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5992, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6027, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6123, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6201, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6114, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6079, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6158, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6087, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6089, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6101, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6067, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6267, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6112, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6193, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6050, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6170, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6142, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6053, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6087, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6153, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6112, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6051, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6156, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6093, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6134, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6088, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6123, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6118, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6025, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5887, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6026, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6130, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6110, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6202, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6083, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6050, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6160, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6073, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6109, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6153, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5987, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6076, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6164, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6008, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6151, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6119, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5981, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5997, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6120, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6062, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6055, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6111, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6098, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6171, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5956, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6120, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6107, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6011, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6167, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6121, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5989, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6208, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6109, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6068, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6077, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6206, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6078, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6103, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6070, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5953, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6011, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6127, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6047, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6045, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6105, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5964, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6125, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6035, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6002, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6159, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5968, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5997, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6101, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6029, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6035, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6032, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6152, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6044, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6160, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6038, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5979, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5999, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6014, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6246, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6054, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6017, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6099, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6114, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6106, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6016, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6201, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6101, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6091, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6021, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6049, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5992, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6023, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6116, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5962, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6115, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6056, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6024, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5917, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6153, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6085, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6184, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6040, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6185, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6108, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6091, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6125, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6058, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6123, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5962, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6088, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5953, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6046, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6044, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5986, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6192, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6023, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5969, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5966, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6057, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6168, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6020, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6276, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6047, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6031, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6158, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6015, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6119, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6051, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6173, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6119, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6126, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6043, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6093, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6114, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6128, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6101, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6017, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6115, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6088, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5949, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6223, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6031, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6154, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6088, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5980, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6035, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.6179, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
[fedaggre.py:266] Round[3]TrainClient2:[1/1], Loss:0.900, DataLength:12207, mean/var:0.034054677933454514/7.886500497988891e-06
loss=tensor(57.6051, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(42.2998, device='cuda:0', grad_fn=<SumBackward0>)
bsz=47
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
[fedaggre.py:281] Round[3]Val_Client[2], Accu[0.010], Loss[0.900]
[fedaggre.py:255] Totally 1024 Pseudo labels
use pseudo
loss=tensor(115.1916, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.1903, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.2039, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.1889, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.1879, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.1876, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.1997, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.1858, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.1864, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.1823, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.1905, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.1844, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.1891, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.1926, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(115.1900, device='cuda:0', grad_fn=<AddBackward0>)
bsz=128
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
use pseudo
loss=tensor(93.5959, device='cuda:0', grad_fn=<AddBackward0>)
bsz=104
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5925, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5971, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5855, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5936, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5915, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5972, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5939, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5854, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5957, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5947, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5878, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5991, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5892, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5877, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5854, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5919, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5861, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5915, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5871, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5876, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5889, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5766, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5932, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5878, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5961, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5969, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5899, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5919, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5892, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5904, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5959, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5908, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5977, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5881, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5956, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5920, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5882, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5909, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5924, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5848, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5912, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5890, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5952, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5870, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5835, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5836, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5951, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5933, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5902, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5807, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5863, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5821, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5893, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5960, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5919, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5908, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5972, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5963, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5915, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5896, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5904, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5925, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5879, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5924, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5870, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5874, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5892, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5868, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5922, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5895, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5832, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5918, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5926, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5889, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5902, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5838, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5897, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5917, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5924, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5972, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5918, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5931, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5854, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5988, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5928, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5965, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5923, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5907, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5945, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5837, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5904, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5912, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5895, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5916, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5935, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5920, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5894, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5949, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5874, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5893, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5885, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5905, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5943, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5931, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5951, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5846, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5951, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5920, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5878, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5969, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5905, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5905, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5894, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5985, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5980, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5889, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5921, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5901, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5872, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5827, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5892, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5886, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5853, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5923, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5929, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5935, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5839, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5870, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5908, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5889, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5899, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5984, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5847, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5852, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5966, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5894, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5933, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5914, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5932, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5966, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5898, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5936, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5989, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5962, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5913, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5910, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5861, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5893, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5952, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5864, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5869, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5868, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5899, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5887, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5934, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5997, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5923, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5905, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5891, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5870, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5942, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5915, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5933, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5899, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5882, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5891, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5932, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5896, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5885, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5936, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5905, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5790, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5911, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5876, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5900, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5901, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5894, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5870, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5935, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5925, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5930, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5837, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5904, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5906, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5848, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5947, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5838, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5928, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5934, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5863, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5850, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5960, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5918, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5854, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5913, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5912, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5864, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5937, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5835, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5875, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5914, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5873, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5876, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5859, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5818, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
[fedaggre.py:266] Round[3]TrainClient3:[1/1], Loss:0.900, DataLength:15385, mean/var:0.03322826325893402/7.301823643501848e-06
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5839, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5972, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5856, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5865, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5903, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5889, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5968, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5812, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5912, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5899, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5900, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5838, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5905, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5943, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5895, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5960, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5808, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5880, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(57.5892, device='cuda:0', grad_fn=<SumBackward0>)
bsz=64
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
loss=tensor(22.4948, device='cuda:0', grad_fn=<SumBackward0>)
bsz=25
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([2048])
param.grad.view(-1).size()=torch.Size([1048576])
param.grad.view(-1).size()=torch.Size([512])
[fedaggre.py:281] Round[3]Val_Client[3], Accu[0.010], Loss[0.900]
[fedaggre.py:360] *** Round[3]: Server_Test_Accu[0.010] *** 
[fedaggre.py:369] -------------------------------------------End All------------------------------------------------
